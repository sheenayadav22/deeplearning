# Deep Learning Project
The Deep Learning Model Development and Analysis Project is a comprehensive exploration of advanced neural network architectures, including Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs), leveraging the power of Python and prominent libraries such as NumPy, Keras, TensorFlow, and SciKit-Learn. This project aims to build, train, and thoroughly analyze these models to unlock insights and drive innovation in the field of artificial intelligence.

## Key Objectives:

### Model Architecture Exploration: 
- Investigate various deep learning architectures, focusing on DNNs and CNNs, to understand their strengths, weaknesses, and suitability for different tasks.

### Implementation with Python:
- Utilize Python as the primary programming language to build and execute the deep learning models, capitalizing on its flexibility, readability, and extensive ecosystem.

### Libraries Utilization:

- NumPy: Employ NumPy for efficient numerical computations, matrix operations, and linear algebra tasks to enhance the computational performance of the models.
- Keras: Leverage Keras as a high-level neural network API to rapidly prototype, train, and evaluate deep learning models, enabling a seamless development process.
- TensorFlow: Combine TensorFlow for its powerful and flexible deep learning framework, providing low-level control over model architecture and training process when needed.
- SciKit-Learn: Integrate SciKit-Learn for a comprehensive suite of machine learning tools, facilitating preprocessing, validation, and performance evaluation of the models.
### Training and Optimization: 
- Employ state-of-the-art training techniques, including backpropagation, gradient descent, and advanced optimization algorithms, to enhance model performance and convergence.

### Performance Evaluation: 
- Conduct rigorous analysis and evaluation of the models using appropriate metrics, such as accuracy, precision, recall, F1-score, and ROC-AUC, to ensure robustness and generalization.

### Hyperparameter Tuning: 
- Fine-tune model hyperparameters to achieve optimal performance, employing techniques like grid search, random search, and Bayesian optimization.

### Visualization and Interpretability: 
- Implement visualization techniques to gain insights into the inner workings of the models, enabling a deeper understanding of feature importance and decision-making processes.

### Application Domains: 
- Explore the applicability of the models across diverse domains, such as computer vision, natural language processing, and time series analysis, showcasing their versatility and adaptability.

## Assignment 1: Logistic Regression, Gradient Descent
- Used NumPy to work with arrays, use its various functions, and uses its various mechanisms such as vectorization and Broadcasting.
- Built a complete Logistic Regression system that that can be used to train on data of any number of features.
- Explored qualitative and quantitative techniques for assessing the quality of the trained model.
## Assignment 2: Neural Networks
- Built a complete Neural Network system that that can be used to train on data of any number of features.
- Implemented back propagation using only NumPy
- Explored the abilities of a neural network on non-linearly-separable data.
- Explored how varying the number of hidden units impact accuracy and overfitting.
## Assignment 3: Deep Neural Networks, Multiclass Classification, and Keras
- Built a modular Neural Network framework that supports basic layer types and components.
- Implemented forward propagation and back propagation in a modular and vectorized fashion for common layer types.
- Implemented new functionalities such as ReLU activation, softmax activation, and categorical cross entropy loss.
- Built a multiclass classifier for both structured and unstructured image data.
- Worked with a real dataset (MNIST) and applied training and validation data sets to evaluate a model
- Used Keras to build and train basic neural networks
## Assignment 4: Convolutional Neural Networks
- Extended the deep learning framework to support Convolutional Neural Networks
- Implemented forward propagation and back propagation in a modular fashion for Convolution, Maxpooling, and Flatten layer types.
- Train convolutional neural networks with my custom framework
- Use Keras to build and train convolutional neural networks
- Use Keras to work with mainstream CNN architectures such as ResNet, and VGG
## Assignment 5: Optimization and Regularization
- Extended my deep learning framework to BatchNorm Layers
- Extended my deep learning framework to Dropout Layers
- Implemented forward propagation and back propagation in a modular fashion for BatchNorm and Dropout layers.
- Explored the use of BatchNorm, Dropout, and L2 regularization in training deep neural networks.
